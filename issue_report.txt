Issue Report: Instant Likes/Bookmarks Update Delay

**Problem:**
Likes and bookmark updates on questions are not reflected instantly in the UI for lists of questions (e.g., general question listings, user bookmarks). 
The changes only appear after the Time To Live (TTL) of the cached data has expired. The direct response from the like/bookmark API calls, however, 
correctly shows the updated counts.

**Cause:**
The backend utilizes Redis caching via `backend/utils/prismaCache.js` and `backend/utils/redisClient.js` to speed up database queries. Specifically, 
the `cachedQuery` function retrieves data from the cache, or fetches it from the database and then caches it.

When a user likes or bookmarks a question, the `toggleLikeQuestion` and `toggleBookmarkQuestion` functions in `backend/controllers/questionController.js` 
correctly attempt to invalidate the relevant cache entries using `invalidateCache`. These invalidation calls target broad patterns such as:
*   `questions:*` (for general question listings)
*   `question:${questionId}` (for a specific question's detail)
*   `courseQuestions:${question.courseId}:*` (for questions within a specific course)
*   `userBookmarks:${userId}:*` (for a specific user's bookmarked questions across all pages/limits)

Despite these explicit invalidation attempts, the observed delay suggests that the cache invalidation is not *immediately* effective or complete for all subsequent 
requests for cached question lists. Several factors could contribute to this:

1.  **Race Condition/Timing Issues:** A subsequent request for a list of questions might be served from the cache *before* the `invalidateCache` 
operation has fully propagated or completed its deletion process within the Redis instance.
2.  **Redis `KEYS` Command Performance:** The `invalidateCache` function uses `redis.keys(keyPattern)` to find all matching keys for deletion. 
While `KEYS` can be fast for small datasets, it can become slow or potentially inconsistent in certain Redis configurations or under heavy load, especially 
in a distributed environment (like Upstash Redis), leading to some keys not being deleted promptly.
3.  **Upstash Specific Behavior:** There might be a specific characteristic of the Upstash Redis service (e.g., eventual consistency in a distributed setup) 
that introduces a minor delay in cache invalidation, making it not truly "instant" in all scenarios.

The core issue is that even though invalidation is requested, the system continues to serve stale cached data for question lists until the original cache 
entries naturally expire due to their TTL.

**Proposed Fix (Conceptual - No Code Changes Requested):**
To ensure instant updates, the focus should be on ensuring immediate and reliable cache invalidation or implementing a more real-time update mechanism.

1.  **Verify Cache Invalidation Effectiveness:**
    *   Thoroughly log the `keys` returned by `redis.keys(keyPattern)` within the `invalidateCache` function to confirm that all expected keys are 
    being identified for deletion.
    *   Monitor Redis logs/metrics (if available) to ensure `DEL` operations are executing promptly after `KEYS` returns.

2.  **Consider More Targeted Invalidation (if patterns are too broad/narrow):**
    *   If `questions:*` is too broad and triggers re-caching too often, consider more specific keys that only invalidate the *exact* lists affected. 
    However, given the current issue, broader invalidation seems necessary.
    *   Conversely, ensure the `*` patterns truly match all variations of the `cachedQuery` keys.

3.  **Real-time Updates (e.g., WebSockets):**
    *   For truly instant updates across all connected clients, consider integrating a WebSocket solution. When a like/bookmark action occurs, 
    the backend invalidates the cache AND sends a WebSocket message to all relevant clients, prompting them to re-fetch the affected data 
    (or update their local state directly). This bypasses caching issues for immediate display.

4.  **Review `cachedQuery` and `invalidateCache` Atomicity:**
    *   Ensure there are no scenarios where `cachedQuery` might inadvertently re-cache stale data between the invalidation call and a subsequent fetch for fresh data.

Essentially, the existing invalidation mechanism needs to be more robust or supplemented with real-time push updates to overcome the perceived delay.